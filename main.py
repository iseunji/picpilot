import streamlit as st
import datetime
import numpy as np
from loguru import logger
from PIL import Image
import io
import torch
import open_clip
import requests

POST_TIMES = {
    "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)": [
        ("ì›”ìš”ì¼", "07:00", "11:00"),
        ("í™”ìš”ì¼", "17:00", "19:00"),
        ("ëª©ìš”ì¼", "09:00", "09:00"),
        ("ê¸ˆìš”ì¼", "06:00", "10:00"),
        ("ê¸ˆìš”ì¼", "17:00", "21:00"),
    ],
    "ì‹ìŒë£Œ / í˜¸í…” / ê´€ê´‘ (Dining, hospitality, and tourism)": [
        ("ìˆ˜ìš”ì¼", "11:00", "15:00"),
    ],
    "ê¸ˆìœµ ì„œë¹„ìŠ¤ (Financial services)": [
        ("ìˆ˜ìš”ì¼", "11:00", "14:00"),
        ("ê¸ˆìš”ì¼", "11:00", "16:00"),
    ],
    "ë¯¸ë””ì–´ / ì—”í„°í…Œì¸ë¨¼íŠ¸ (Media and entertainment)": [
        ("ì¼ìš”ì¼", "13:00", "13:00"),
        ("í™”ìš”ì¼", "07:00", "08:00"),
        ("ìˆ˜ìš”ì¼", "17:00", "17:00"),
        ("ê¸ˆìš”ì¼", "14:00", "16:00"),
    ],
    "í—¬ìŠ¤ì¼€ì–´ / ë°”ì´ì˜¤ / ì œì•½ (Healthcare, pharma, and biotech)": [
        ("ì›”ìš”ì¼", "13:00", "15:00"),
        ("ëª©ìš”ì¼", "09:00", "12:00"),
        ("í† ìš”ì¼", "08:00", "11:00"),
    ],
    "ë§ˆì¼€íŒ… / ê´‘ê³  (Marketing agencies)": [
        ("ì›”ìš”ì¼", "09:00", "11:00"),
        ("ê¸ˆìš”ì¼", "08:00", "10:00"),
    ],
    "ë¹„ì˜ë¦¬ (Nonprofit)": [
        ("ìˆ˜ìš”ì¼", "10:00", "13:00"),
        ("ëª©ìš”ì¼", "14:00", "17:00"),
    ],
    "ê±´ì„¤ / ì œì¡° / ê´‘ì—… (Construction, mining, and manufacturing)": [
        ("í™”ìš”ì¼", "15:00", "18:00"),
        ("ìˆ˜ìš”ì¼", "14:00", "17:00"),
        ("ëª©ìš”ì¼", "16:00", "18:00"),
    ],
    "ì—ë„ˆì§€ / ê³µê³µì„œë¹„ìŠ¤ (Utilities and energy)": [
        ("í™”ìš”ì¼", "14:00", "17:00"),
        ("ëª©ìš”ì¼", "13:00", "15:00"),
    ],
    "ì •ë¶€ (Government)": [
        ("ëª©ìš”ì¼", "12:00", "15:00"),
    ],
}

GENERIC_POST_TIMES = [
    ("ì›”ìš”ì¼", "15:00", "21:00"),
    ("í™”ìš”ì¼", "05:00", "08:00"),
    ("í™”ìš”ì¼", "15:00", "19:00"),
    ("ìˆ˜ìš”ì¼", "17:00", "17:00"),
    ("ëª©ìš”ì¼", "16:00", "17:00"),
    ("ê¸ˆìš”ì¼", "16:00", "16:00"),
    ("í† ìš”ì¼", "11:00", "11:00"),
    ("í† ìš”ì¼", "17:00", "17:00"),
    ("ì¼ìš”ì¼", "12:00", "15:00"),
]

CREATOR_TO_FIELD = {
    "ë·°í‹°": "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)",
    "íŒ¨ì…˜": "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)",
    "ì‹í’ˆ": "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)",
    "ìƒí™œìš©í’ˆ": "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)",
    "í™ˆì‡¼í•‘": "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)",
    "ì‡¼í•‘ëª°": "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)",
    "ì œí’ˆ í˜‘ì°¬": "ì†Œë¹„ì¬ / ì†Œë§¤ (Consumer goods and retail)",
    "ì—¬í–‰": "ì‹ìŒë£Œ / í˜¸í…” / ê´€ê´‘ (Dining, hospitality, and tourism)",
    "í˜¸í…”": "ì‹ìŒë£Œ / í˜¸í…” / ê´€ê´‘ (Dining, hospitality, and tourism)",
    "ë ˆìŠ¤í† ë‘": "ì‹ìŒë£Œ / í˜¸í…” / ê´€ê´‘ (Dining, hospitality, and tourism)",
    "íˆ¬ì": "ê¸ˆìœµ ì„œë¹„ìŠ¤ (Financial services)",
    "ì¬í…Œí¬": "ê¸ˆìœµ ì„œë¹„ìŠ¤ (Financial services)",
    "ê²½ì œ": "ê¸ˆìœµ ì„œë¹„ìŠ¤ (Financial services)",
    "ê¸ˆìœµ": "ê¸ˆìœµ ì„œë¹„ìŠ¤ (Financial services)",
    "Q&A": "ê¸ˆìœµ ì„œë¹„ìŠ¤ (Financial services)",
    "ì—°ì˜ˆ": "ë¯¸ë””ì–´ / ì—”í„°í…Œì¸ë¨¼íŠ¸ (Media and entertainment)",
    "ë°´ë“œ": "ë¯¸ë””ì–´ / ì—”í„°í…Œì¸ë¨¼íŠ¸ (Media and entertainment)",
    "ë°ˆ": "ë¯¸ë””ì–´ / ì—”í„°í…Œì¸ë¨¼íŠ¸ (Media and entertainment)",
    "ìœ ë¨¸": "ë¯¸ë””ì–´ / ì—”í„°í…Œì¸ë¨¼íŠ¸ (Media and entertainment)",
    "ê²Œì„": "ë¯¸ë””ì–´ / ì—”í„°í…Œì¸ë¨¼íŠ¸ (Media and entertainment)",
    "ì›¹íˆ°": "ë¯¸ë””ì–´ / ì—”í„°í…Œì¸ë¨¼íŠ¸ (Media and entertainment)",
    "ê±´ê°•": "í—¬ìŠ¤ì¼€ì–´ / ë°”ì´ì˜¤ / ì œì•½ (Healthcare, pharma, and biotech)",
    "ìš´ë™": "í—¬ìŠ¤ì¼€ì–´ / ë°”ì´ì˜¤ / ì œì•½ (Healthcare, pharma, and biotech)",
    "í”¼íŠ¸ë‹ˆìŠ¤": "í—¬ìŠ¤ì¼€ì–´ / ë°”ì´ì˜¤ / ì œì•½ (Healthcare, pharma, and biotech)",
    "ì˜ì–‘": "í—¬ìŠ¤ì¼€ì–´ / ë°”ì´ì˜¤ / ì œì•½ (Healthcare, pharma, and biotech)",
    "í—¬ìŠ¤ì¼€ì–´": "í—¬ìŠ¤ì¼€ì–´ / ë°”ì´ì˜¤ / ì œì•½ (Healthcare, pharma, and biotech)",
    "ë””ì§€í„¸ ë§ˆì¼€íŒ…": "ë§ˆì¼€íŒ… / ê´‘ê³  (Marketing agencies)",
    "ë§ˆì¼€íŒ…": "ë§ˆì¼€íŒ… / ê´‘ê³  (Marketing agencies)",
    "íˆ´": "ë§ˆì¼€íŒ… / ê´‘ê³  (Marketing agencies)",
    "ë…¸í•˜ìš°": "ë§ˆì¼€íŒ… / ê´‘ê³  (Marketing agencies)",
    "íŠ¹ìˆ˜ ì§êµ°": "ê±´ì„¤ / ì œì¡° / ê´‘ì—… (Construction, mining, and manufacturing)",
    "ì‚°ì—…ê¸°ìˆ ": "ê±´ì„¤ / ì œì¡° / ê´‘ì—… (Construction, mining, and manufacturing)",
    "ê±´ì„¤": "ê±´ì„¤ / ì œì¡° / ê´‘ì—… (Construction, mining, and manufacturing)",
    "ì œì¡°": "ê±´ì„¤ / ì œì¡° / ê´‘ì—… (Construction, mining, and manufacturing)",
    "ê´‘ì—…": "ê±´ì„¤ / ì œì¡° / ê´‘ì—… (Construction, mining, and manufacturing)",
    "ì¹œí™˜ê²½": "ì—ë„ˆì§€ / ê³µê³µì„œë¹„ìŠ¤ (Utilities and energy)",
    "ì—ë„ˆì§€": "ì—ë„ˆì§€ / ê³µê³µì„œë¹„ìŠ¤ (Utilities and energy)",
    "ê³µê³µì„œë¹„ìŠ¤": "ì—ë„ˆì§€ / ê³µê³µì„œë¹„ìŠ¤ (Utilities and energy)",
    "ê³µê³µ ì •ì±…": "ì •ë¶€ (Government)",
    "ë²•ë¥ ": "ì •ë¶€ (Government)",
    "ê³µê³µ ë°ì´í„°": "ì •ë¶€ (Government)",
}

def load_test_images():
    """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ë“¤ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        data_dir = Path("data")
        user_images_dir = data_dir / "user_images"
        candidate_images_dir = data_dir / "candidate_images"
        
        # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        
        # ì‚¬ìš©ì ì´ë¯¸ì§€ë“¤ ë¡œë“œ
        user_images = []
        if user_images_dir.exists():
            for file_path in user_images_dir.iterdir():
                if file_path.suffix.lower() in image_extensions:
                    try:
                        with open(file_path, 'rb') as f:
                            image_bytes = f.read()
                            # StreamlitUploadedFileê³¼ ìœ ì‚¬í•œ ê°ì²´ ìƒì„±
                            class MockUploadedFile:
                                def __init__(self, name, data):
                                    self.name = name
                                    self._data = data
                                    self._position = 0
                                
                                def read(self):
                                    return self._data
                                
                                def seek(self, position):
                                    self._position = position
                            
                            user_images.append(MockUploadedFile(file_path.name, image_bytes))
                        logger.info(f"ì‚¬ìš©ì ì´ë¯¸ì§€ ë¡œë“œ: {file_path.name}")
                    except Exception as e:
                        logger.error(f"ì‚¬ìš©ì ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ {file_path.name}: {e}")
        
        # í›„ë³´ ì´ë¯¸ì§€ë“¤ ë¡œë“œ
        candidate_images = []
        if candidate_images_dir.exists():
            for file_path in candidate_images_dir.iterdir():
                if file_path.suffix.lower() in image_extensions:
                    try:
                        with open(file_path, 'rb') as f:
                            image_bytes = f.read()
                            candidate_images.append(MockUploadedFile(file_path.name, image_bytes))
                        logger.info(f"í›„ë³´ ì´ë¯¸ì§€ ë¡œë“œ: {file_path.name}")
                    except Exception as e:
                        logger.error(f"í›„ë³´ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ {file_path.name}: {e}")
        
        logger.info(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: ì‚¬ìš©ì {len(user_images)}ì¥, í›„ë³´ {len(candidate_images)}ì¥")
        return user_images, candidate_images
        
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return [], []

def map_creator_to_field(user_input: str) -> str:
    for keyword, field in CREATOR_TO_FIELD.items():
        if keyword in user_input:
            return field
    return None

def get_next_best_time(audience: str, now: datetime.datetime = None) -> str:
    if now is None:
        now = datetime.datetime.now()
    today_idx = now.weekday()  # ì›”:0, ì¼:6
    days = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]

    if not audience or audience not in POST_TIMES:
        time_table = GENERIC_POST_TIMES
        info = "ë¶„ì•¼ ë¯¸ì„ íƒ/ëª¨ë¦„/í•´ë‹¹ ì—†ìŒ - ë³´í¸ì  ì¶”ì²œ"
    else:
        time_table = POST_TIMES[audience]
        info = f"{audience} ë¶„ì•¼"

    candidates = []
    for day, start, end in time_table:
        day_idx = days.index(day)
        delta_days = (day_idx - today_idx) % 7
        post_date = now + datetime.timedelta(days=delta_days)
        start_dt = datetime.datetime.combine(post_date.date(), datetime.time.fromisoformat(start))
        if start_dt < now:
            start_dt += datetime.timedelta(days=7)
        if start==end:
            candidates.append((start_dt, f"{day} {start}"))
        else:
            candidates.append((start_dt, f"{day} {start}~{end}"))
    if not candidates:
        return "ì¶”ì²œ ì—…ë¡œë“œ ì‹œê°„ì´ ì—†ìŠµë‹ˆë‹¤."
    candidates.sort()
    return f"{info}ì˜ ê°€ì¥ ê°€ê¹Œìš´ ì¶”ì²œ ì—…ë¡œë“œ ì‹œê°„: {candidates[0][1]}"

def load_clip_model():
    """open_clip ê¸°ë°˜ CLIP ëª¨ë¸ ë¡œë“œ"""
    try:
        logger.info("open_clip ëª¨ë¸ ë¡œë”© ì¤‘...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')
        model = model.to(device)
        logger.info(f"open_clip ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {device})")
        return model, preprocess, device
    except Exception as e:
        logger.error(f"open_clip ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None, None

def calculate_clip_similarity(img1_bytes, img2_bytes, model, preprocess, device):
    """open_clipì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        img1 = Image.open(io.BytesIO(img1_bytes)).convert('RGB')
        img2 = Image.open(io.BytesIO(img2_bytes)).convert('RGB')
        img1_tensor = preprocess(img1).unsqueeze(0).to(device)
        img2_tensor = preprocess(img2).unsqueeze(0).to(device)
        with torch.no_grad():
            img1_features = model.encode_image(img1_tensor)
            img2_features = model.encode_image(img2_tensor)
            img1_features = img1_features / img1_features.norm(dim=-1, keepdim=True)
            img2_features = img2_features / img2_features.norm(dim=-1, keepdim=True)
            similarity = (img1_features @ img2_features.T).item()
        return similarity
    except Exception as e:
        logger.error(f"open_clip ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

_clip_model = None
_clip_preprocess = None
_clip_device = None

def get_clip_model():
    global _clip_model, _clip_preprocess, _clip_device
    if _clip_model is None:
        _clip_model, _clip_preprocess, _clip_device = load_clip_model()
    return _clip_model, _clip_preprocess, _clip_device

def calculate_image_similarity(img1_bytes, img2_bytes):
    model, preprocess, device = get_clip_model()
    if model is not None:
        return calculate_clip_similarity(img1_bytes, img2_bytes, model, preprocess, device)
    else:
        logger.warning("open_clip ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
        return 0.0

def find_most_similar_image(user_images, candidate_images):
    logger.info("clip ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ë¶„ì„ ì‹œì‘")
    best_idx = 0
    best_similarity = -1
    for i, candidate_img in enumerate(candidate_images):
        candidate_bytes = candidate_img.read()
        candidate_img.seek(0)
        similarities = []
        for user_img in user_images:
            user_bytes = user_img.read()
            user_img.seek(0)
            similarity = calculate_image_similarity(user_bytes, candidate_bytes)
            similarities.append(similarity)
        avg_similarity = np.mean(similarities)
        logger.info(f"í›„ë³´ ì´ë¯¸ì§€ {i+1} í‰ê·  ìœ ì‚¬ë„: {avg_similarity:.4f}")
        if avg_similarity > best_similarity:
            best_similarity = avg_similarity
            best_idx = i
    logger.info(f"ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ì¸ë±ìŠ¤: {best_idx}, ìœ ì‚¬ë„: {best_similarity:.4f}")
    return best_idx

def generate_caption_with_llm(captions, image_desc="ì‚¬ì§„"):
    API_URL = "https://api-inference.huggingface.co/models/google/gemma-2b-it"
    headers = {}
    prompt = (
        "ì•„ë˜ëŠ” ì¸ìŠ¤íƒ€ê·¸ë¨ ì‚¬ì§„ ìº¡ì…˜ ì˜ˆì‹œì…ë‹ˆë‹¤:\n"
        + "\n".join(captions[:5])
        + f"\n\nìœ„ ìŠ¤íƒ€ì¼ì„ ì°¸ê³ í•´ì„œ, '{image_desc}'ì— ì–´ìš¸ë¦¬ëŠ” ì§§ì€ ì½”ë©˜íŠ¸ì™€ í•´ì‹œíƒœê·¸ 2ê°œë¥¼ ì¶”ì²œí•´ì¤˜."
    )
    payload = {"inputs": prompt, "parameters": {"max_new_tokens": 60}}
    try:
        response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
        result = response.json()
        if isinstance(result, list) and len(result) > 0 and "generated_text" in result[0]:
            return result[0]["generated_text"]
        elif "generated_text" in result:
            return result["generated_text"]
        elif "error" in result:
            return f"LLM ì˜¤ë¥˜: {result['error']}"
        else:
            return str(result)
    except Exception as e:
        return f"ìº¡ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

def main():
    st.title("PicPilot Agent")
    st.markdown(
        """
        ì•ˆë…•í•˜ì„¸ìš”. ë‹¹ì‹ ì˜ ì¸ìŠ¤íƒ€ê·¸ë¨ ì—…ë¡œë“œìš© ì‚¬ì§„ì„ ê³¨ë¼ë“œë¦´ Picpilot ì…ë‹ˆë‹¤.

        <span style="font-size:1.00em; font-weight:300;">
        Picpilotì€<br>
        âœ… ë‹¹ì‹ ì˜ ì„ í˜¸ ì´ë¯¸ì§€ ë° ìº¡ì…˜ ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•˜ê³ <br>
        âœ… ì—¬ëŸ¬ í›„ë³´ ì‚¬ì§„ ì¤‘ ê°€ì¥ ì í•©í•œ ì´ë¯¸ì§€ì™€ ê·¸ì— ì–´ìš¸ë¦¬ëŠ” ìº¡ì…˜ì„ ì¶”ì²œ í•˜ë©°<br>
        âœ… ì¶”ì²œ ì—…ë¡œë“œ ìš”ì¼/ì‹œê°„ê¹Œì§€ ì œì•ˆí•˜ëŠ” AI ê¸°ë°˜ ì¸ìŠ¤íƒ€ê·¸ë¨ ì—…ë¡œë“œ ë³´ì¡° ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
        </span>
        """,
        unsafe_allow_html=True
    )

    st.markdown('<div style="font-size:1.25em; font-weight:600; margin-top:1.5em;">ğŸ”¹ ë³¸ì¸ì´ ì£¼ë¡œ í™œë™í•˜ê±°ë‚˜, íƒ€ê²Ÿìœ¼ë¡œ í•˜ëŠ” ë¶„ì•¼</div>', unsafe_allow_html=True)
    user_field_input = st.text_input("ì˜ˆì‹œ: ë·°í‹° ë¦¬ë·°, ì—¬í–‰, íˆ¬ì ì½˜í…ì¸  í¬ë¦¬ì—ì´í„° ë“± / ë¶„ì•¼ íŠ¹ì •ì„ ì›ì¹˜ ì•Šê±°ë‚˜ ëª¨í˜¸í•œ ê²½ìš° 'ì—†ìŒ' ìœ¼ë¡œ í‘œê¸° ê°€ëŠ¥")

    audience = None
    if user_field_input:
        audience = map_creator_to_field(user_field_input)
        if audience:
            st.success(f"ì…ë ¥í•˜ì‹  ë‚´ìš©ì´ '{audience}' ë¶„ì•¼ë¡œ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì…ë ¥í•˜ì‹  ë‚´ìš©ì´ ê¸°ì¡´ ë¶„ì•¼ ë¦¬ìŠ¤íŠ¸ì™€ ë§¤ì¹­ë˜ì§€ ì•Šì•„, ë³´í¸ì  ì¶”ì²œì´ ì ìš©ë©ë‹ˆë‹¤.")

    st.markdown('<div style="font-size:1.25em; font-weight:600; margin-top:1.5em;">ğŸ”¹ ë³¸ì¸ì˜ ìŠ¤íƒ€ì¼ì„ ë³´ì—¬ì£¼ê±°ë‚˜, ì„ í˜¸í•˜ëŠ” ì¸ìŠ¤íƒ€ê·¸ë¨ ì‚¬ì§„ 5-10ì¥</div>', unsafe_allow_html=True)
    user_images = st.file_uploader("ì‚¬ì§„ ì—…ë¡œë“œ (ìµœëŒ€ 10ì¥)", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

    st.markdown('<div style="font-size:1.25em; font-weight:600; margin-top:1.5em;">ğŸ”¹ ê¸°ì¡´ì— ì˜¬ë ¸ë˜ ì´ë¯¸ì§€ ìº¡ì…˜ê³¼ íƒœê·¸ ì˜ˆì‹œ 5ê°œ ì´ìƒ (í•œ ì¤„ì— í•˜ë‚˜ì”©)</div>', unsafe_allow_html=True)
    captions = st.text_area("ì˜ˆì‹œ: ë„ˆë¬´ í–‰ë³µí–ˆë˜ ì¼ë³¸ ì—¬í–‰!ğŸ’— #ì—¬í–‰ìŠ¤íƒ€ê·¸ë¨ #OOTD ë“±").splitlines()

    st.markdown('<div style="font-size:1.25em; font-weight:600; margin-top:1.5em;">ğŸ”¹ ì—…ë¡œë“œë¥¼ í¬ë§í•˜ëŠ” í›„ë³´ ì‚¬ì§„ 2-10ì¥</div>', unsafe_allow_html=True)
    candidate_images = st.file_uploader("ì‚¬ì§„ ì—…ë¡œë“œ (ìµœëŒ€ 10ì¥)", type=["jpg", "jpeg", "png"], accept_multiple_files=True, key="candidate")

    # ë¶„ì„ ë°©ë²• ì„ íƒ ë“œë¡­ë‹¤ìš´ (ë³´ì—¬ì£¼ê¸°ìš©, ì‹¤ì œë¡œëŠ” clipë§Œ ë™ì‘)
    analysis_method = st.selectbox(
        "ì´ë¯¸ì§€ ìœ ì‚¬ë„ ë¶„ì„ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”",
        [
            "clip (ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼/ì˜ë¯¸ ê¸°ë°˜)",
            "histogram (ì´ë¯¸ì§€ ìƒ‰ìƒ ê¸°ë°˜)",
            "orb (ì´ë¯¸ì§€ êµ¬ì¡° ê¸°ë°˜, íŠ¹ì§• ë§¤ì¹­)"
        ],
        index=0,
        help="ê¸°íšì„œì— ëª…ì‹œëœ ë‹¤ì–‘í•œ ë¶„ì„ ë°©ë²•ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ì˜µì…˜ì…ë‹ˆë‹¤. í˜„ì¬ ë²„ì „ ì˜¤ë¥˜ë¡œ CLIP ê¸°ë°˜ìœ¼ë¡œë§Œ ë™ì‘í•©ë‹ˆë‹¤."
    )
    # st.info("â€» í˜„ì¬ Streamlit Cloudì—ì„œëŠ” CLIP ê¸°ë°˜ ì¶”ì²œë§Œ ì‹¤ì œë¡œ ë™ì‘í•©ë‹ˆë‹¤. (ìƒ‰ìƒ/êµ¬ì¡° ê¸°ë°˜ì€ ì‹œì—°ìš© UI)")

    if st.button("ì—…ë¡œë“œ ì´ë¯¸ì§€ ì¶”ì²œ"):
        if user_images and candidate_images:
            if len(candidate_images) < 2:
                st.warning("í›„ë³´ ì‚¬ì§„ì„ 2ì¥ ì´ìƒ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ì´ë¯¸ì§€ ìœ ì‚¬ë„ ë¶„ì„ ì¤‘..."):
                    try:
                        logger.info("ì´ë¯¸ì§€ ìœ ì‚¬ë„ ë¶„ì„ ì‹œì‘")
                        # ì‹¤ì œ ë¶„ì„ì€ clipë§Œ ì‚¬ìš©
                        best_idx = find_most_similar_image(user_images, candidate_images)
                        logger.info("ì´ë¯¸ì§€ ìœ ì‚¬ë„ ë¶„ì„ ì™„ë£Œ")
                        best_image = candidate_images[best_idx]
                        st.image(best_image, caption="ê°€ì¥ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ì˜ ì¶”ì²œ ì´ë¯¸ì§€")
                        if captions:
                            with st.spinner("ì¶”ì²œ ìº¡ì…˜ ìƒì„± ì¤‘..."):
                                gen_caption = generate_caption_with_llm(captions, image_desc="ì¶”ì²œ ì´ë¯¸ì§€")
                            st.markdown("**ì¶”ì²œ ì½”ë©˜íŠ¸ ë° í•´ì‹œíƒœê·¸:**")
                            st.write(gen_caption)
                        best_time = get_next_best_time(audience)
                        st.write(best_time)
                    except Exception as e:
                        logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
                        st.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            st.warning("ê¸°ì¡´ ì‚¬ì§„ê³¼ í›„ë³´ ì‚¬ì§„ì„ ëª¨ë‘ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()